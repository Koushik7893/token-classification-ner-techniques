{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# BiLSTM-CRF with BIO tagging, word embeddings, char-LSTM\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0jaL0pmOFLA",
        "outputId": "45aea9cc-955c-49e3-a31f-504f72ee8153"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers torch datasets accelerate scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🔹 Downloading the Dataset\n",
        "\n",
        "We begin by downloading the CoNLL-2003 dataset from Kaggle using `kagglehub`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmR_aeO8orLw",
        "outputId": "d11e4a7b-5336-42ed-c676-74b518599bef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/juliangarratt/conll2003-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 960k/960k [00:00<00:00, 104MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/juliangarratt/conll2003-dataset/versions/1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"juliangarratt/conll2003-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🔹 Extracting and Organizing Files\n",
        "\n",
        "The downloaded files are moved to a specified directory for easy access and further processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "n1ZJy7IfowPI",
        "outputId": "3722bd8e-86ca-4e74-e53f-b9e9e7362a45"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/conll2003-dataset'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "shutil.move(path, \"/content/conll2003-dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuB36EUtqu0g"
      },
      "source": [
        "## Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🔹 Reading the Dataset\n",
        "\n",
        "A custom parser function reads `.txt` files and extracts sentences and their corresponding NER labels in a structured format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ojfy16Wn6L4",
        "outputId": "58ae8313-a52b-4f09-9f48-028400cad0b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example:\n",
            "[('EU', 'B-ORG'), ('rejects', 'O'), ('German', 'B-MISC'), ('call', 'O'), ('to', 'O'), ('boycott', 'O'), ('British', 'B-MISC'), ('lamb', 'O'), ('.', 'O')]\n"
          ]
        }
      ],
      "source": [
        "def read_conll2003(file_path):\n",
        "    sentences, labels = [], []\n",
        "    words, tags = [], []\n",
        "\n",
        "    with open(file_path, encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            if line.startswith(\"-DOCSTART\") or line == \"\" or line == \"\\n\":\n",
        "                if words:\n",
        "                    sentences.append(words)\n",
        "                    labels.append(tags)\n",
        "                    words, tags = [], []\n",
        "            else:\n",
        "                splits = line.strip().split()\n",
        "                words.append(splits[0])\n",
        "                tags.append(splits[-1])  # Use NER tag\n",
        "        if words:\n",
        "            sentences.append(words)\n",
        "            labels.append(tags)\n",
        "    return sentences, labels\n",
        "\n",
        "train_sents, train_labels = read_conll2003(\"/content/conll2003-dataset/conll2003/train.txt\")\n",
        "val_sents, val_labels = read_conll2003(\"/content/conll2003-dataset/conll2003/testa.txt\")\n",
        "test_sents, test_labels = read_conll2003(\"/content/conll2003-dataset/conll2003/testb.txt\")\n",
        "\n",
        "print(f\"Example:\\n{list(zip(train_sents[0], train_labels[0]))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALlMN1zwn6JL",
        "outputId": "f825ae3b-c88a-4937-efd5-36f5b86e359b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(14041, 3250, 3453)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_sents), len(val_sents), len(test_sents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vocabulary Construction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKHGY-IAqxqu"
      },
      "source": [
        "### 🔹 Word & Tag Vocabulary\n",
        "\n",
        "We construct `word2idx` and `tag2idx` mappings to convert text and labels into numerical format suitable for model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GEQHxcyln6Gg"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from itertools import chain\n",
        "\n",
        "PAD = \"<PAD>\"\n",
        "UNK = \"<UNK>\"\n",
        "\n",
        "def build_vocab(sentences, min_freq=1):\n",
        "    word_counter = Counter(chain(*sentences))\n",
        "    vocab = {word for word, freq in word_counter.items() if freq >= min_freq}\n",
        "    idx2word = [PAD, UNK] + sorted(vocab)\n",
        "    word2idx = {w: i for i, w in enumerate(idx2word)}\n",
        "    return word2idx, idx2word\n",
        "\n",
        "def build_tag_map(labels):\n",
        "    tags = sorted(set(tag for seq in labels for tag in seq))\n",
        "    tag2idx = {tag: i for i, tag in enumerate(tags)}\n",
        "    idx2tag = {i: tag for tag, i in tag2idx.items()}\n",
        "    return tag2idx, idx2tag\n",
        "\n",
        "word2idx, idx2word = build_vocab(train_sents)\n",
        "tag2idx, idx2tag = build_tag_map(train_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHcVsjezq0hr"
      },
      "source": [
        "### 🔹 Character-Level Vocabulary\n",
        "\n",
        "Character-level vocabularies are built to support char-level embeddings, enabling better handling of unknown or rare words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9ted8QMUn6EB"
      },
      "outputs": [],
      "source": [
        "def build_char_vocab(sentences):\n",
        "    chars = set(c for word in chain(*sentences) for c in word)\n",
        "    idx2char = [PAD, UNK] + sorted(chars)\n",
        "    char2idx = {c: i for i, c in enumerate(idx2char)}\n",
        "    return char2idx, idx2char\n",
        "\n",
        "char2idx, idx2char = build_char_vocab(train_sents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSa5smqBq25g"
      },
      "source": [
        "### 🔹 Encoding Words and Characters\n",
        "\n",
        "Sentences are tokenized into word and character indices using the created vocabularies. Character tokens are padded or truncated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eZnMAI3n6Bb"
      },
      "outputs": [],
      "source": [
        "def encode_words(sentences, word2idx):\n",
        "    return [[word2idx.get(w, word2idx[UNK]) for w in sent] for sent in sentences]\n",
        "\n",
        "def encode_chars(sentences, char2idx, max_word_len=15):\n",
        "    encoded = []\n",
        "    for sent in sentences:\n",
        "        sent_chars = []\n",
        "        for word in sent:\n",
        "            char_ids = [char2idx.get(c, char2idx[UNK]) for c in word]\n",
        "            # pad or truncate\n",
        "            char_ids = char_ids[:max_word_len] + [char2idx[PAD]] * (max_word_len - len(char_ids))\n",
        "            sent_chars.append(char_ids)\n",
        "        encoded.append(sent_chars)\n",
        "    return encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🔹 Encoding Labels\n",
        "\n",
        "NER tags are encoded into integer labels using the tag-to-index map."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def encode_labels(labels, tag2idx):\n",
        "    return [[tag2idx[t] for t in seq] for seq in labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okt_IDXZrwT4",
        "outputId": "534c1bc8-7458-4fd4-b198-b741d207c5d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([[6420, 20821, 7229, 14822, 22700, 14673, 5084, 18390, 125], [10721, 4911]],\n",
              " [['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'],\n",
              "  ['Peter', 'Blackburn']])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encode_words(train_sents[:2], word2idx), train_sents[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OKG-zFFrD9X"
      },
      "source": [
        "## Dataset and DataLoader\n",
        "\n",
        "### 🔹 Creating a PyTorch Dataset Class\n",
        "\n",
        "A custom `NERDataset` class is defined to serve word, character, and label sequences in a format suitable for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmmoFr1un5-u"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class NERDataset(Dataset):\n",
        "    def __init__(self, sentences, labels, word2idx, char2idx, tag2idx, max_word_len=15):\n",
        "        self.word_ids = encode_words(sentences, word2idx)\n",
        "        self.char_ids = encode_chars(sentences, char2idx, max_word_len)\n",
        "        self.tag_ids = encode_labels(labels, tag2idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.word_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"words\": torch.tensor(self.word_ids[idx], dtype=torch.long),\n",
        "            \"chars\": torch.tensor(self.char_ids[idx], dtype=torch.long),\n",
        "            \"labels\": torch.tensor(self.tag_ids[idx], dtype=torch.long),\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🔹 Collate Function\n",
        "\n",
        "A `collate_fn` is defined to pad sequences properly for batch processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    words = [item[\"words\"] for item in batch]\n",
        "    chars = [item[\"chars\"] for item in batch]\n",
        "    labels = [item[\"labels\"] for item in batch]\n",
        "\n",
        "    # pad word sequences\n",
        "    words_padded = pad_sequence(words, batch_first=True)\n",
        "    labels_padded = pad_sequence(labels, batch_first=True)\n",
        "\n",
        "    # pad char sequences\n",
        "    max_sent_len = max([c.shape[0] for c in chars])\n",
        "    max_word_len = chars[0].shape[1]\n",
        "    padded_chars = torch.zeros((len(chars), max_sent_len, max_word_len), dtype=torch.long)\n",
        "    for i, char_seq in enumerate(chars):\n",
        "        padded_chars[i, :char_seq.shape[0], :] = char_seq\n",
        "\n",
        "    return words_padded, padded_chars, labels_padded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WwI4XzIrQ7n"
      },
      "source": [
        "## Model Architecture\n",
        "\n",
        "### 🔹 BiLSTM-CRF Overview\n",
        "\n",
        "We design a model combining word embeddings, character-level BiLSTM, word-level BiLSTM, and a CRF layer for structured prediction.\n",
        "\n",
        "### 🔹 Word and Character Embeddings\n",
        "\n",
        "Separate embedding layers are used for words and characters to capture both lexical and sub-word features.\n",
        "\n",
        "### 🔹 BiLSTM Layers\n",
        "\n",
        "The concatenated embeddings are passed through a bidirectional LSTM to learn contextual representations.\n",
        "\n",
        "### 🔹 CRF Layer\n",
        "\n",
        "A CRF layer is added on top to model tag dependencies and improve sequence labeling performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WKPO-rtCnSyu"
      },
      "outputs": [],
      "source": [
        "!pip install -q pytorch-crf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xvbfNL0Nn57z"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torchcrf import CRF  # pip install pytorch-crf\n",
        "\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "    def __init__(self, vocab_size, char_vocab_size, tagset_size,\n",
        "                 word_emb_dim=100, char_emb_dim=30, char_hidden_dim=50,\n",
        "                 word_hidden_dim=200, char_max_len=15):\n",
        "\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "\n",
        "        # Word Embedding\n",
        "        self.word_emb = nn.Embedding(vocab_size, word_emb_dim, padding_idx=0)\n",
        "\n",
        "        # Char Embedding + Char LSTM\n",
        "        self.char_emb = nn.Embedding(char_vocab_size, char_emb_dim, padding_idx=0)\n",
        "        self.char_lstm = nn.LSTM(input_size=char_emb_dim, hidden_size=char_hidden_dim,\n",
        "                                 batch_first=True, bidirectional=True)\n",
        "\n",
        "        # BiLSTM over word + char\n",
        "        self.lstm = nn.LSTM(input_size=word_emb_dim + char_hidden_dim * 2,\n",
        "                            hidden_size=word_hidden_dim, batch_first=True, bidirectional=True)\n",
        "\n",
        "        # Final tag classifier\n",
        "        self.hidden2tag = nn.Linear(word_hidden_dim * 2, tagset_size)\n",
        "\n",
        "        # CRF\n",
        "        self.crf = CRF(tagset_size, batch_first=True)\n",
        "\n",
        "    def forward(self, words, chars, labels=None, mask=None):\n",
        "        batch_size, sent_len = words.shape\n",
        "        _, _, word_len = chars.shape\n",
        "\n",
        "        # Word embeddings\n",
        "        word_embeds = self.word_emb(words)  # [B, T, D]\n",
        "\n",
        "        # Char embeddings\n",
        "        chars = chars.view(-1, word_len)  # [B*T, W]\n",
        "        char_embeds = self.char_emb(chars)  # [B*T, W, D]\n",
        "        _, (h_n, _) = self.char_lstm(char_embeds)  # h_n: [2, B*T, H]\n",
        "        char_repr = torch.cat([h_n[0], h_n[1]], dim=-1)  # [B*T, 2H]\n",
        "        char_repr = char_repr.view(batch_size, sent_len, -1)  # [B, T, 2H]\n",
        "\n",
        "        # Concatenate word and char representations\n",
        "        combined = torch.cat([word_embeds, char_repr], dim=-1)  # [B, T, D+2H]\n",
        "\n",
        "        # BiLSTM\n",
        "        lstm_out, _ = self.lstm(combined)  # [B, T, 2H]\n",
        "\n",
        "        emissions = self.hidden2tag(lstm_out)  # [B, T, num_tags]\n",
        "\n",
        "        # Apply CRF\n",
        "        if labels is not None:\n",
        "            loss = -self.crf(emissions, labels, mask=mask, reduction='mean')\n",
        "            return loss\n",
        "        else:\n",
        "            prediction = self.crf.decode(emissions, mask=mask)\n",
        "            return prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3ovCUpWhn55E"
      },
      "outputs": [],
      "source": [
        "def create_mask(words, pad_idx=0):\n",
        "    return (words != pad_idx).type(torch.uint8)  # [B, T]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPVyYe_jn52I",
        "outputId": "2e63a208-dff5-4d66-c0d9-bd35d2432584"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q seqeval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🔹 Evaluation Metrics\n",
        "\n",
        "We use `seqeval` to compute the F1 score and classification report, which are essential for evaluating NER performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "kkn1ZP97n5y9"
      },
      "outputs": [],
      "source": [
        "from seqeval.metrics import classification_report, f1_score, accuracy_score\n",
        "\n",
        "def compute_metrics(true_tags, pred_tags):\n",
        "    # print(classification_report(true_tags, pred_tags))\n",
        "    print(f\"F1 Score: {f1_score(true_tags, pred_tags):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "SQVPabPPn5wO"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_model(model, train_ds, val_ds, tag2idx, idx2tag, epochs=3, batch_size=32, lr=1e-3):\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        train_iter = tqdm(train_loader, desc=f\"Epoch {epoch} - Training\", leave=False)\n",
        "\n",
        "        for words, chars, labels in train_iter:\n",
        "            mask = create_mask(words).to(device)\n",
        "            words, chars, labels = words.to(device), chars.to(device), labels.to(device)\n",
        "\n",
        "            loss = model(words, chars, labels, mask=mask)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            train_iter.set_postfix(loss=loss.item())\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch}: Train Loss = {avg_loss:.4f}\")\n",
        "        evaluate_model(model, val_loader, idx2tag, device)\n",
        "\n",
        "def evaluate_model(model, loader, idx2tag, device):\n",
        "    model.eval()\n",
        "    true_tags, pred_tags = [], []\n",
        "\n",
        "    eval_iter = tqdm(loader, desc=\"Evaluating\", leave=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for words, chars, labels in eval_iter:\n",
        "            mask = create_mask(words).to(device)\n",
        "            words, chars = words.to(device), chars.to(device)\n",
        "            preds = model(words, chars, mask=mask)\n",
        "\n",
        "            for i in range(len(preds)):\n",
        "                real_len = mask[i].sum().item()\n",
        "                pred_seq = [idx2tag[idx] for idx in preds[i][:real_len]]\n",
        "                true_seq = [idx2tag[idx.item()] for idx in labels[i][:real_len]]\n",
        "                pred_tags.append(pred_seq)\n",
        "                true_tags.append(true_seq)\n",
        "\n",
        "    compute_metrics(true_tags, pred_tags)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inference\n",
        "\n",
        "### 🔹 Making Predictions\n",
        "\n",
        "A utility function allows inference on new sentences, predicting NER tags using the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "D_6ZpiNkn5tZ"
      },
      "outputs": [],
      "source": [
        "def infer(model, sentence, word2idx, char2idx, idx2tag, device):\n",
        "    model.eval()\n",
        "    tokens = sentence.split()\n",
        "    word_ids = torch.tensor([[word2idx.get(w, word2idx[UNK]) for w in tokens]])\n",
        "    char_ids = torch.tensor([[[char2idx.get(c, char2idx[UNK]) for c in w[:15]] +\n",
        "                              [char2idx[PAD]]*(15 - len(w)) for w in tokens]])\n",
        "\n",
        "    mask = create_mask(word_ids).to(device)\n",
        "    word_ids, char_ids = word_ids.to(device), char_ids.to(device)\n",
        "    preds = model(word_ids, char_ids, mask=mask)[0]\n",
        "\n",
        "    return list(zip(tokens, [idx2tag[i] for i in preds]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "GhuF_8IBosl0"
      },
      "outputs": [],
      "source": [
        "train_ds = NERDataset(train_sents, train_labels, word2idx, char2idx, tag2idx)\n",
        "val_ds   = NERDataset(val_sents, val_labels, word2idx, char2idx, tag2idx)\n",
        "test_ds = NERDataset(test_sents, test_labels, word2idx, char2idx, tag2idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETABqwq4pHyM"
      },
      "outputs": [],
      "source": [
        "model = BiLSTM_CRF(\n",
        "    vocab_size=len(word2idx),\n",
        "    char_vocab_size=len(char2idx),\n",
        "    tagset_size=len(tag2idx),\n",
        "    word_emb_dim=100,\n",
        "    char_emb_dim=30,\n",
        "    char_hidden_dim=50,\n",
        "    word_hidden_dim=200,\n",
        "    char_max_len=15\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lyuweig9pJr0",
        "outputId": "2a07e6ee-10bf-4950-d9da-9e0ac721af39"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Train Loss = 4.8780\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.6871\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: Train Loss = 1.5689\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.7677\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: Train Loss = 0.8658\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.7849\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: Train Loss = 0.4519\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.8163\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: Train Loss = 0.2200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.8273\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6: Train Loss = 0.0985\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.8206\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7: Train Loss = 0.0404\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.8340\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8: Train Loss = 0.0215\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.8347\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9: Train Loss = 0.0129\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.8323\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10: Train Loss = 0.0079\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.8251\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "train_model(\n",
        "    model=model,\n",
        "    train_ds=train_ds,\n",
        "    val_ds=val_ds,\n",
        "    tag2idx=tag2idx,\n",
        "    idx2tag=idx2tag,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    lr=1e-3\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🔹 Inference Example\n",
        "\n",
        "A sample sentence is passed through the model to visualize its NER tagging capability.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVPSV9Mqn5q8",
        "outputId": "4182b93c-59d3-4f35-f4cb-6668e0040461"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('Barack', 'O'), ('Obama', 'I-PER'), ('was', 'O'), ('born', 'O'), ('in', 'O'), ('Hawaii', 'B-LOC'), ('.', 'O')]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Define the device in the global scope\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "sentence = \"Barack Obama was born in Hawaii .\"\n",
        "predicted_tags = infer(model, sentence, word2idx, char2idx, idx2tag, device)\n",
        "print(predicted_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkEgNnVun5oX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjQrCImJn5lo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0dl_3gkn5i2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9YRFZhln5gg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NRwjTI_n5eK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bej2NArvn5bO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3rF9KNun5Y6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWkFkbSZn5Wk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPNNZszan5T_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XF0m0ykun5Rb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCeWwHdfn5O7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7iisDW4n5MO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-eGYf2On5Jt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hb8KKwsUn5Gt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbnvoJ76n4do"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 612351,
          "sourceId": 1095715,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31041,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
